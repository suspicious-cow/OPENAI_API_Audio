{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univeral Code Used for the Entire Notebook\n",
    "\n",
    "Let's set up our libraries and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages for handling sound files and sound devices\n",
    "# Uncomment the following line if you need to install the packages\n",
    "# !pip install soundfile sounddevice\n",
    "# !pip install pyaudio\n",
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # For interacting with the operating system\n",
    "import requests  # For making HTTP requests\n",
    "from io import BytesIO  # For handling byte streams\n",
    "\n",
    "import soundfile as sf  # For reading and writing sound files\n",
    "import sounddevice as sd  # For playing and recording sound\n",
    "import pyaudio\n",
    "\n",
    "from IPython.display import Audio, display, clear_output, Markdown  # For displaying content in Jupyter Notebooks\n",
    "\n",
    "from openai import OpenAI, AssistantEventHandler  # For OpenAI API and event handling\n",
    "from typing_extensions import override  # For method overriding in subclasses\n",
    "\n",
    "from pathlib import Path\n",
    "import openai\n",
    "from IPython.display import display, HTML\n",
    "import pyaudio\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()  # Initialize the OpenAI client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating an Audio File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the openai api library approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the speech file path\n",
    "speech_file_path = \"./fight_on_the_beaches.mp3\"\n",
    "\n",
    "# Create the TTS (Text-to-Speech) request\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1-hd\",  # Specify the TTS model to use\n",
    "    voice=\"fable\",  # Specify the voice to use for the TTS\n",
    "    input=\"\"\"\n",
    "    Even though large tracts of Europe and many old and famous States have fallen or may fall into the grip of the Gestapo and all the odious apparatus of Nazi rule, we shall not flag or fail. We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in Godâ€™s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.\n",
    "    \"\"\"  # Input text to be converted to speech\n",
    ")\n",
    "\n",
    "# Save the response audio to a file\n",
    "with open(speech_file_path, 'wb') as file:\n",
    "    file.write(response.content)  # Write the audio content to the file\n",
    "\n",
    "# Print a message indicating where the audio was saved\n",
    "print(f\"Audio saved to {speech_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the API endpoint approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the speech file path\n",
    "speech_file_path = \"./old_soldiers_never_die.mp3\"\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# API endpoint and headers\n",
    "url = \"https://api.openai.com/v1/audio/speech\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Data payload for the request\n",
    "data = {\n",
    "    \"model\": \"tts-1\",\n",
    "    \"voice\": \"shimmer\",\n",
    "    \"input\": \"\"\"\n",
    "    I still remember the refrain of one of the most popular barracks ballads of that day which proclaimed most proudly that old soldiers never die; they just fade away. And like the old soldier of that ballad, I now close my military career and just fade away, an old soldier who tried to do his duty as God gave him the light to see that duty.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Make the synchronous request\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    with open(speech_file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Audio saved to {speech_file_path}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Chat Completion and Assistant Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Completion to Audio without End-to-End Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the speech file path\n",
    "speech_file_path = \"./war_message_to_congress.mp3\"\n",
    "\n",
    "# Create the chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to use\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # System message to set the assistant's behavior\n",
    "        {\"role\": \"user\", \"content\": \"Give me one paragraph on penguins\"}  # User message to initiate the conversation\n",
    "    ],\n",
    "    stream=True  # Enable streaming responses\n",
    ")\n",
    "\n",
    "# Capture the chat output in real-time\n",
    "chat_output = \"\"\n",
    "for chunk in chat_completion:\n",
    "    delta = chunk.choices[0].delta\n",
    "    content = getattr(delta, 'content', None)  # Safely get the content attribute\n",
    "    if content:\n",
    "        print(content, end='')  # Print without newline to maintain the flow\n",
    "        chat_output += content\n",
    "\n",
    "# API endpoint and headers for TTS\n",
    "url = \"https://api.openai.com/v1/audio/speech\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Data payload for the TTS request\n",
    "data = {\n",
    "    \"model\": \"tts-1-hd\",\n",
    "    \"voice\": \"onyx\",\n",
    "    \"input\": chat_output,  # Use chat output as input for TTS\n",
    "    \"response_format\": \"mp3\"  # Use MP3 format for response\n",
    "}\n",
    "\n",
    "# Make the TTS request with streaming enabled\n",
    "response = requests.post(url, headers=headers, json=data, stream=True)\n",
    "\n",
    "# Check if the TTS request was successful\n",
    "if response.status_code == 200:\n",
    "    buffer = BytesIO()\n",
    "\n",
    "    # Save audio chunks to file and buffer\n",
    "    with open(speech_file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                buffer.write(chunk)\n",
    "    \n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Read and play the audio from the buffer\n",
    "    data, samplerate = sf.read(buffer)\n",
    "    sd.play(data, samplerate)\n",
    "    sd.wait()  # Wait until the audio playback is done\n",
    "\n",
    "    print(f\"Audio saved to {speech_file_path}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistant to Audio without End-to-end Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "OpenAI.api_key = api_key\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize an empty list to store the results\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Append the delta value (partial text) to the results list\n",
    "        text = delta.value\n",
    "        self.results.append(text)\n",
    "        # Call the method to update the Jupyter Notebook cell\n",
    "        self.update_output()\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        # Clear the current output in the Jupyter Notebook cell\n",
    "        clear_output(wait=True)\n",
    "        # Join all the text fragments stored in results to form the complete markdown content\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        # Display the markdown content in the Jupyter Notebook cell\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "    def get_complete_response(self):\n",
    "        \"\"\"Return the complete response as a single string.\"\"\"\n",
    "        return \"\".join(self.results)\n",
    "\n",
    "def text_to_speech(text, api_key):\n",
    "    \"\"\"Convert text to speech and play the audio.\"\"\"\n",
    "    tts_url = \"https://api.openai.com/v1/audio/speech\"\n",
    "    tts_headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    tts_model = \"tts-1-hd\"\n",
    "    voice = \"onyx\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": tts_model,\n",
    "        \"voice\": voice,\n",
    "        \"input\": text,\n",
    "        \"response_format\": \"mp3\"\n",
    "    }\n",
    "    response = requests.post(tts_url, headers=tts_headers, json=data, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        buffer = BytesIO()\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                buffer.write(chunk)\n",
    "        buffer.seek(0)\n",
    "        data, samplerate = sf.read(buffer)\n",
    "        sd.play(data, samplerate)\n",
    "        sd.wait()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    instructions=\"You are a helpful assistant.\",  # Instructions for the assistant.\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Create a new assistant thread with an initial user message\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Give me one paragraph on penguins\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create an instance of the custom event handler\n",
    "event_handler = EventHandler()\n",
    "\n",
    "# Stream the assistant's response\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    assistant_id=assistant.id,  # Specify the assistant ID.\n",
    "    event_handler=event_handler,  # Use the custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n",
    "\n",
    "# Get the complete response from the event handler\n",
    "complete_response = event_handler.get_complete_response()\n",
    "\n",
    "# Convert the complete response to speech\n",
    "text_to_speech(complete_response, api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating an Audio File with Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the openai api library approach\n",
    "\n",
    "(doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the speech file path\n",
    "speech_file_path = \"./wonderfulday.mp3\"\n",
    "\n",
    "# Create the TTS (Text-to-Speech) request\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",  # Specify the TTS model to use\n",
    "    voice=\"alloy\",  # Specify the voice to use for the TTS\n",
    "    input=\"Today is a wonderful day to build something people love!\"  # Input text to be converted to speech\n",
    ")\n",
    "\n",
    "# Save the response audio to a file using stream_to_file method\n",
    "response.stream_to_file(speech_file_path)\n",
    "\n",
    "# Print a message indicating where the audio was saved\n",
    "print(f\"Audio saved to {speech_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the openai api library approach\n",
    "\n",
    "(corrected version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to ./wonderfulday.mp3\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the speech file path\n",
    "speech_file_path = \"./wonderfulday.mp3\"\n",
    "\n",
    "# Create the TTS (Text-to-Speech) request using the recommended method\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Today is a wonderful day to build something people love!\"\n",
    ") as response:\n",
    "    with open(speech_file_path, 'wb') as f:\n",
    "        for chunk in response.iter_bytes():\n",
    "            f.write(chunk)\n",
    "\n",
    "# Print a message indicating where the audio was saved\n",
    "print(f\"Audio saved to {speech_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize OpenAI client with your API key\n",
    "client = OpenAI()\n",
    "\n",
    "# Initialize PyAudio, which provides bindings for PortAudio, a cross-platform audio library\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open a stream with specific audio format parameters\n",
    "stream = p.open(format=pyaudio.paInt16,  # Format: 16-bit PCM (Pulse Code Modulation)\n",
    "                channels=1,              # Channels: 1 (Mono)\n",
    "                rate=24000,              # Sample rate: 24,000 Hz (samples per second)\n",
    "                output=True)             # Stream opened for output (playback)\n",
    "\n",
    "# Function to stream and play audio in real-time\n",
    "def stream_audio():\n",
    "    # Create a TTS (Text-to-Speech) request\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=\"tts-1\",                   # Specify the TTS model to use\n",
    "        voice=\"alloy\",                   # Specify the voice to use for TTS\n",
    "        input=\"\"\"\n",
    "    The present German submarine warfare against commerce is a warfare against mankind.\n",
    "\n",
    "    It is war against all nations.\n",
    "\n",
    "    American ships have been sunk, American lives taken, in ways which it has stirred us very deeply to learn of, but the ships and people of other neutral and friendly nations have been sunk and overwhelmed in the waters in the same way. There has been no discrimination. The challenge is to all mankind.\n",
    "\n",
    "    Each nation must decide for itself how it will meet it. The choice we make for ourselves must be made with a moderation of counsel and temperateness of judgment befitting our character and our motives as a nation. We must put excited feeling away. Our motive will not be revenge or the victorious assertion of the physical might of the nation, but only the vindication of right, of human right, of which we are only a single champion.\n",
    "    \"\"\",  # Input text to be converted to speech\n",
    "        response_format=\"pcm\"            # Response format: PCM (Pulse Code Modulation)\n",
    "    ) as response:\n",
    "        # Iterate over the audio chunks in the response\n",
    "        for chunk in response.iter_bytes(1024):  # Read 1024 bytes at a time\n",
    "            stream.write(chunk)  # Write each chunk to the PyAudio stream for playback\n",
    "\n",
    "# Start streaming and playing the audio\n",
    "stream_audio()\n",
    "\n",
    "# Close the PyAudio stream properly\n",
    "stream.stop_stream()  # Stop the stream\n",
    "stream.close()        # Close the stream\n",
    "p.terminate()         # Terminate the PyAudio session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Chat Completion and Assistant Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Completion to Audio with End-to-End Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Space exploration is a pivotal endeavor for humanity, fostering technological innovation, scientific discovery, and international collaboration. It propels advancements in various fields, including engineering, materials science, and medicine, often yielding technologies that benefit everyday life, such as satellite communications and GPS. By studying celestial bodies and phenomena, we gain insights into the origins and evolution of our solar system and the potential for life beyond Earth. Additionally, the challenges of space travel drive the development of sustainable practices and resource management, which have applications on our home planet. Ultimately, space exploration inspires curiosity and ambition, pushing us to overcome boundaries and envision a future where humanity is capable of thriving beyond our terrestrial confines."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to use\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # System message to set the assistant's behavior\n",
    "        {\"role\": \"user\", \"content\": \"Give me a paragraph about the importance of space exploration.\"}  # User message to initiate the conversation\n",
    "    ],\n",
    "    stream=True  # Enable streaming responses\n",
    ")\n",
    "\n",
    "# Function to stream the response\n",
    "def stream_response(chat_completion):\n",
    "    full_response = \"\"\n",
    "    display_id = display(HTML(full_response), display_id=True)\n",
    "    for chunk in chat_completion:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            full_response += chunk.choices[0].delta.content\n",
    "            display_id.update(HTML(full_response))\n",
    "\n",
    "# Call the function to stream the response\n",
    "stream_response(chat_completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Space exploration plays a crucial role in the advancement of human knowledge and innovation. It opens a gateway to discover the mysteries beyond our planet, giving us insights into the origins and vastness of the universe. It spurs technological innovation, from satellite technology to advanced materials, which often have practical applications on Earth. Furthermore, space exploration plays a vital role in inspiring future generations to pursue careers in science, technology, engineering, and mathematics. It fosters international cooperation and promotes peaceful interactions between nations. Ultimately, the pursuit of knowledge and survival drives space exploration, as it equips us better to face potential extraterrestrial threats and paves the way for potential future habitation of other planets."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open a stream with specific audio format parameters\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=1,\n",
    "                rate=24000,\n",
    "                output=True)\n",
    "\n",
    "# Create separate queues for text and audio chunks\n",
    "text_queue = queue.Queue()\n",
    "sentence_queue = queue.Queue()\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "# Flags for process control\n",
    "text_generation_complete = threading.Event()\n",
    "sentence_processing_complete = threading.Event()\n",
    "audio_generation_complete = threading.Event()\n",
    "\n",
    "def generate_and_display_text():\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Give me a paragraph about the importance of space exploration.\"}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "    display_id = display(HTML(full_response), display_id=True)\n",
    "    \n",
    "    for chunk in chat_completion:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            new_text = chunk.choices[0].delta.content\n",
    "            full_response += new_text\n",
    "            display_id.update(HTML(full_response))\n",
    "            text_queue.put(new_text)\n",
    "    \n",
    "    text_generation_complete.set()\n",
    "\n",
    "def process_sentences():\n",
    "    sentence_buffer = \"\"\n",
    "    while not (text_generation_complete.is_set() and text_queue.empty()):\n",
    "        try:\n",
    "            new_text = text_queue.get(timeout=0.1)\n",
    "            sentence_buffer += new_text\n",
    "            sentences = re.findall(r'[^.!?]+[.!?]', sentence_buffer)\n",
    "            for sentence in sentences:\n",
    "                sentence_queue.put(sentence.strip())\n",
    "            sentence_buffer = re.sub(r'.*[.!?]', '', sentence_buffer)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "    \n",
    "    if sentence_buffer:\n",
    "        sentence_queue.put(sentence_buffer.strip())\n",
    "    \n",
    "    sentence_processing_complete.set()\n",
    "\n",
    "def generate_audio():\n",
    "    while not (sentence_processing_complete.is_set() and sentence_queue.empty()):\n",
    "        try:\n",
    "            sentence = sentence_queue.get(timeout=0.5)\n",
    "            with client.audio.speech.with_streaming_response.create(\n",
    "                model=\"tts-1\",\n",
    "                voice=\"alloy\",\n",
    "                input=sentence,\n",
    "                response_format=\"pcm\"\n",
    "            ) as response:\n",
    "                for audio_chunk in response.iter_bytes(1024):\n",
    "                    audio_queue.put(audio_chunk)\n",
    "            \n",
    "            # Add a short pause between sentences\n",
    "            audio_queue.put(b'\\x00' * 4800)  # 0.1 seconds of silence at 24000 Hz\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "    \n",
    "    audio_generation_complete.set()\n",
    "\n",
    "def play_audio():\n",
    "    audio_started = False\n",
    "    while not (audio_generation_complete.is_set() and audio_queue.empty()):\n",
    "        try:\n",
    "            audio_chunk = audio_queue.get(timeout=0.5)\n",
    "            stream.write(audio_chunk)\n",
    "            if not audio_started:\n",
    "                audio_started = True\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "    \n",
    "\n",
    "# Start text generation and display in a separate thread\n",
    "text_thread = threading.Thread(target=generate_and_display_text)\n",
    "text_thread.start()\n",
    "\n",
    "# Start sentence processing in a separate thread\n",
    "sentence_thread = threading.Thread(target=process_sentences)\n",
    "sentence_thread.start()\n",
    "\n",
    "# Start audio generation in a separate thread\n",
    "audio_gen_thread = threading.Thread(target=generate_audio)\n",
    "audio_gen_thread.start()\n",
    "\n",
    "# Wait a short moment before starting audio playback\n",
    "time.sleep(1)\n",
    "\n",
    "# Start audio playback in a separate thread\n",
    "audio_play_thread = threading.Thread(target=play_audio)\n",
    "audio_play_thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "text_thread.join()\n",
    "sentence_thread.join()\n",
    "audio_gen_thread.join()\n",
    "audio_play_thread.join()\n",
    "\n",
    "# Close the PyAudio stream properly\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistant to Audio with End-to-end Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Penguins are fascinating flightless birds primarily found in the Southern Hemisphere, with a significant population in Antarctica. These unique creatures are well-adapted to their cold environments with their distinctive black and white plumage and a thick layer of blubber. Penguins are exceptional swimmers, able to dive to great depths and swim at impressive speeds to catch their prey, which mainly consists of fish, squid, and krill. They exhibit remarkable social behaviors, often huddling together for warmth and engaging in elaborate mating rituals. Despite their seemingly clumsy waddles on land, penguins are agile and graceful in the water, showcasing nature's incredible adaptability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self, batch_interval=5):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize an empty list to store the results\n",
    "        self.tts_url = \"https://api.openai.com/v1/audio/speech\"\n",
    "        self.tts_headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        self.tts_model = \"tts-1-hd\"\n",
    "        self.voice = \"onyx\"\n",
    "        self.buffer = BytesIO()\n",
    "        self.batch_interval = batch_interval  # Time interval for batching in seconds\n",
    "        self.last_batch_time = time.time()\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Append the delta value (partial text) to the results list\n",
    "        text = delta.value\n",
    "        self.results.append(text)\n",
    "        # Call the method to update the Jupyter Notebook cell\n",
    "        self.update_output()\n",
    "\n",
    "        # Check if it's time to send a batch to TTS\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_batch_time >= self.batch_interval:\n",
    "            self.batch_to_tts()\n",
    "            self.last_batch_time = current_time\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        # Clear the current output in the Jupyter Notebook cell\n",
    "        clear_output(wait=True)\n",
    "        # Join all the text fragments stored in results to form the complete markdown content\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        # Display the markdown content in the Jupyter Notebook cell\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "    \n",
    "\n",
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    instructions=\"You are a helpful assistant.\",  # Instructions for the assistant.\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Create a new assistant thread with an initial user message\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Give me one paragraph on penguins\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create an instance of the custom event handler\n",
    "event_handler = EventHandler(batch_interval=5)  # Adjust batch interval as needed\n",
    "\n",
    "# Stream the assistant's response\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    assistant_id=assistant.id,  # Specify the assistant ID.\n",
    "    event_handler=event_handler,  # Use the custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Penguins are a unique group of flightless birds known for their distinctive black and white plumage and their incredible adaptation to life in the ocean. Predominantly found in the Southern Hemisphere, with the majority residing in Antarctica, these birds have evolved to withstand extreme cold with their thick layers of blubber and tightly packed feathers. Penguins are also exceptional swimmers, using their flipper-like wings to propel themselves through the water with remarkable agility in pursuit of fish, krill, and other sea creatures. On land, they exhibit a range of fascinating behaviors, such as intricate courtship rituals and communal nesting practices, making them one of the most captivating avian species."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import pyaudio\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from IPython.display import clear_output, display, Markdown\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []\n",
    "        self.text_buffer = \"\"\n",
    "        self.sentence_queue = queue.Queue()\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.text_generation_complete = threading.Event()\n",
    "\n",
    "        # Initialize PyAudio\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=24000,\n",
    "            output=True)\n",
    "\n",
    "        # Start audio processing and playback threads\n",
    "        self.audio_processing_thread = threading.Thread(target=self.process_sentences)\n",
    "        self.audio_processing_thread.start()\n",
    "        self.audio_playback_thread = threading.Thread(target=self.play_audio)\n",
    "        self.audio_playback_thread.start()\n",
    "\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        text = delta.value\n",
    "        self.results.append(text)\n",
    "        self.text_buffer += text\n",
    "        self.process_text_buffer()\n",
    "        self.update_output()\n",
    "\n",
    "    def process_text_buffer(self):\n",
    "        sentences = re.findall(r'[^.!?]+[.!?]', self.text_buffer)\n",
    "        for sentence in sentences:\n",
    "            self.sentence_queue.put(sentence.strip())\n",
    "        self.text_buffer = re.sub(r'.*[.!?]', '', self.text_buffer)\n",
    "\n",
    "    def update_output(self):\n",
    "        clear_output(wait=True)\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "    def process_sentences(self):\n",
    "        while not self.text_generation_complete.is_set() or not self.sentence_queue.empty():\n",
    "            try:\n",
    "                sentence = self.sentence_queue.get(timeout=0.1)\n",
    "                with client.audio.speech.with_streaming_response.create(\n",
    "                    model=\"tts-1\",\n",
    "                    voice=\"onyx\",\n",
    "                    input=sentence,\n",
    "                    response_format=\"pcm\"\n",
    "                ) as response:\n",
    "                    for audio_chunk in response.iter_bytes(1024):\n",
    "                        self.audio_queue.put(audio_chunk)\n",
    "                # Add a short pause between sentences\n",
    "                self.audio_queue.put(b'\\x00' * 2400)  # 0.05 seconds of silence at 24000 Hz\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "\n",
    "    def play_audio(self):\n",
    "        while not self.text_generation_complete.is_set() or not self.audio_queue.empty():\n",
    "            try:\n",
    "                audio_chunk = self.audio_queue.get(timeout=0.1)\n",
    "                self.stream.write(audio_chunk)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.p.terminate()\n",
    "\n",
    "    def on_end(self):\n",
    "        # Process any remaining text in the buffer\n",
    "        self.process_text_buffer()\n",
    "        if self.text_buffer:\n",
    "            self.sentence_queue.put(self.text_buffer.strip())\n",
    "        \n",
    "        self.text_generation_complete.set()\n",
    "        self.audio_processing_thread.join()\n",
    "        self.audio_playback_thread.join()\n",
    "\n",
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "# Create a new assistant thread with an initial user message\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Give me one paragraph on penguins\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create an instance of the custom event handler\n",
    "event_handler = EventHandler()\n",
    "\n",
    "# Stream the assistant's response\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    event_handler=event_handler,\n",
    ") as stream:\n",
    "    stream.until_done()\n",
    "\n",
    "event_handler.on_end()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
