{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univeral Code Used for the Entire Notebook\n",
    "\n",
    "Let's set up our libraries and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages for handling sound files and sound devices\n",
    "# Uncomment the following line if you need to install the packages\n",
    "# !pip install soundfile sounddevice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # For interacting with the operating system\n",
    "import requests  # For making HTTP requests\n",
    "from io import BytesIO  # For handling byte streams\n",
    "\n",
    "import soundfile as sf  # For reading and writing sound files\n",
    "import sounddevice as sd  # For playing and recording sound\n",
    "\n",
    "from IPython.display import Audio, display, clear_output, Markdown  # For displaying content in Jupyter Notebooks\n",
    "\n",
    "from openai import OpenAI, AssistantEventHandler  # For OpenAI API and event handling\n",
    "from typing_extensions import override  # For method overriding in subclasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()  # Initialize the OpenAI client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Audio without Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the openai api library approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the speech file path\n",
    "speech_file_path = \"./fight_on_the_beaches.mp3\"\n",
    "\n",
    "# Create the TTS (Text-to-Speech) request\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1-hd\",  # Specify the TTS model to use\n",
    "    voice=\"fable\",  # Specify the voice to use for the TTS\n",
    "    input=\"\"\"\n",
    "    Even though large tracts of Europe and many old and famous States have fallen or may fall into the grip of the Gestapo and all the odious apparatus of Nazi rule, we shall not flag or fail. We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in Godâ€™s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.\n",
    "    \"\"\"  # Input text to be converted to speech\n",
    ")\n",
    "\n",
    "# Save the response audio to a file\n",
    "with open(speech_file_path, 'wb') as file:\n",
    "    file.write(response.content)  # Write the audio content to the file\n",
    "\n",
    "# Print a message indicating where the audio was saved\n",
    "print(f\"Audio saved to {speech_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the API endpoint approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the speech file path\n",
    "speech_file_path = \"./old_soldiers_never_die.mp3\"\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# API endpoint and headers\n",
    "url = \"https://api.openai.com/v1/audio/speech\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Data payload for the request\n",
    "data = {\n",
    "    \"model\": \"tts-1\",\n",
    "    \"voice\": \"shimmer\",\n",
    "    \"input\": \"\"\"\n",
    "    I still remember the refrain of one of the most popular barracks ballads of that day which proclaimed most proudly that old soldiers never die; they just fade away. And like the old soldier of that ballad, I now close my military career and just fade away, an old soldier who tried to do his duty as God gave him the light to see that duty.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Make the synchronous request\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    with open(speech_file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Audio saved to {speech_file_path}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Completion to Audio without End-to-End Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI  # Import OpenAI module for interacting with the OpenAI API\n",
    "import os  # os module for interacting with the operating system\n",
    "import requests  # requests module for making HTTP requests\n",
    "import soundfile as sf  # soundfile module for reading and writing sound files\n",
    "import sounddevice as sd  # sounddevice module for playing and recording sound\n",
    "from io import BytesIO  # BytesIO module for handling byte streams\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the speech file path\n",
    "speech_file_path = \"./war_message_to_congress.mp3\"\n",
    "\n",
    "# Create the chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to use\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # System message to set the assistant's behavior\n",
    "        {\"role\": \"user\", \"content\": \"Give me one paragraph on penguins\"}  # User message to initiate the conversation\n",
    "    ],\n",
    "    stream=True  # Enable streaming responses\n",
    ")\n",
    "\n",
    "# Capture the chat output in real-time\n",
    "chat_output = \"\"\n",
    "for chunk in chat_completion:\n",
    "    delta = chunk.choices[0].delta\n",
    "    content = getattr(delta, 'content', None)  # Safely get the content attribute\n",
    "    if content:\n",
    "        print(content, end='')  # Print without newline to maintain the flow\n",
    "        chat_output += content\n",
    "\n",
    "# API endpoint and headers for TTS\n",
    "url = \"https://api.openai.com/v1/audio/speech\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Data payload for the TTS request\n",
    "data = {\n",
    "    \"model\": \"tts-1-hd\",\n",
    "    \"voice\": \"onyx\",\n",
    "    \"input\": chat_output,  # Use chat output as input for TTS\n",
    "    \"response_format\": \"mp3\"  # Use MP3 format for response\n",
    "}\n",
    "\n",
    "# Make the TTS request with streaming enabled\n",
    "response = requests.post(url, headers=headers, json=data, stream=True)\n",
    "\n",
    "# Check if the TTS request was successful\n",
    "if response.status_code == 200:\n",
    "    buffer = BytesIO()\n",
    "\n",
    "    # Save audio chunks to file and buffer\n",
    "    with open(speech_file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                buffer.write(chunk)\n",
    "    \n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Read and play the audio from the buffer\n",
    "    data, samplerate = sf.read(buffer)\n",
    "    sd.play(data, samplerate)\n",
    "    sd.wait()  # Wait until the audio playback is done\n",
    "\n",
    "    print(f\"Audio saved to {speech_file_path}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistant to Audio without End-to-end Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "OpenAI.api_key = api_key\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize an empty list to store the results\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Append the delta value (partial text) to the results list\n",
    "        text = delta.value\n",
    "        self.results.append(text)\n",
    "        # Call the method to update the Jupyter Notebook cell\n",
    "        self.update_output()\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        # Clear the current output in the Jupyter Notebook cell\n",
    "        clear_output(wait=True)\n",
    "        # Join all the text fragments stored in results to form the complete markdown content\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        # Display the markdown content in the Jupyter Notebook cell\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "    def get_complete_response(self):\n",
    "        \"\"\"Return the complete response as a single string.\"\"\"\n",
    "        return \"\".join(self.results)\n",
    "\n",
    "def text_to_speech(text, api_key):\n",
    "    \"\"\"Convert text to speech and play the audio.\"\"\"\n",
    "    tts_url = \"https://api.openai.com/v1/audio/speech\"\n",
    "    tts_headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    tts_model = \"tts-1-hd\"\n",
    "    voice = \"onyx\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": tts_model,\n",
    "        \"voice\": voice,\n",
    "        \"input\": text,\n",
    "        \"response_format\": \"mp3\"\n",
    "    }\n",
    "    response = requests.post(tts_url, headers=tts_headers, json=data, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        buffer = BytesIO()\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                buffer.write(chunk)\n",
    "        buffer.seek(0)\n",
    "        data, samplerate = sf.read(buffer)\n",
    "        sd.play(data, samplerate)\n",
    "        sd.wait()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    instructions=\"You are a helpful assistant.\",  # Instructions for the assistant.\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Create a new assistant thread with an initial user message\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Give me one paragraph on penguins\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create an instance of the custom event handler\n",
    "event_handler = EventHandler()\n",
    "\n",
    "# Stream the assistant's response\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    assistant_id=assistant.id,  # Specify the assistant ID.\n",
    "    event_handler=event_handler,  # Use the custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n",
    "\n",
    "# Get the complete response from the event handler\n",
    "complete_response = event_handler.get_complete_response()\n",
    "\n",
    "# Convert the complete response to speech\n",
    "text_to_speech(complete_response, api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the openai api library approach\n",
    "\n",
    "(doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the speech file path\n",
    "speech_file_path = \"./wonderfulday.mp3\"\n",
    "\n",
    "# Create the TTS (Text-to-Speech) request\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",  # Specify the TTS model to use\n",
    "    voice=\"alloy\",  # Specify the voice to use for the TTS\n",
    "    input=\"Today is a wonderful day to build something people love!\"  # Input text to be converted to speech\n",
    ")\n",
    "\n",
    "# Save the response audio to a file using stream_to_file method\n",
    "response.stream_to_file(speech_file_path)\n",
    "\n",
    "# Print a message indicating where the audio was saved\n",
    "print(f\"Audio saved to {speech_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the API endpoint approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the speech file path\n",
    "speech_file_path = \"./war_message_to_congress.mp3\"\n",
    "\n",
    "# API endpoint and headers\n",
    "url = \"https://api.openai.com/v1/audio/speech\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Data payload for the request\n",
    "data = {\n",
    "    \"model\": \"tts-1-hd\",\n",
    "    \"voice\": \"onyx\",\n",
    "    \"input\": \"\"\"\n",
    "    The present German submarine warfare against commerce is a warfare against mankind.\n",
    "\n",
    "It is war against all nations.\n",
    "\n",
    "American ships have been sunk, American lives taken, in ways which it has stirred us very deeply to learn of, but the ships and people of other neutral and friendly nations have been sunk and overwhelmed in the waters in the same way. There has been no discrimination. The challenge is to all mankind.\n",
    "\n",
    "Each nation must decide for itself how it will meet it. The choice we make for ourselves must be made with a moderation of counsel and temperateness of judgment befitting our character and our motives as a nation. We must put excited feeling away. Our motive will not be revenge or the victorious assertion of the physical might of the nation, but only the vindication of right, of human right, of which we are only a single champion.\n",
    "    \"\"\",\n",
    "    \"response_format\": \"mp3\"  # Use MP3 format for response\n",
    "}\n",
    "\n",
    "# Make the request with streaming enabled\n",
    "response = requests.post(url, headers=headers, json=data, stream=True)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    buffer = BytesIO()\n",
    "\n",
    "    # Save audio chunks to file and buffer\n",
    "    with open(speech_file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                buffer.write(chunk)\n",
    "    \n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Read and play the audio from the buffer\n",
    "    data, samplerate = sf.read(buffer)\n",
    "    sd.play(data, samplerate)\n",
    "    sd.wait()  # Wait until the audio playback is done\n",
    "\n",
    "    print(f\"Audio saved to {speech_file_path}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Chat Completions to TTS for Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the chat completion request\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to use\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # System message to set the assistant's behavior\n",
    "        {\"role\": \"user\", \"content\": \"Give me one paragraph on penguins\"}  # User message to initiate the conversation\n",
    "    ],\n",
    "    stream=True  # Enable streaming responses\n",
    ")\n",
    "\n",
    "# Iterate over the streamed response chunks and print the content\n",
    "for chunk in completion:\n",
    "    delta = chunk.choices[0].delta\n",
    "    content = getattr(delta, 'content', None)  # Safely get the content attribute\n",
    "    if content:\n",
    "        print(content, end='')  # Print without newline to maintain the flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the speech file path\n",
    "speech_file_path = \"./war_message_to_congress.mp3\"\n",
    "\n",
    "# Create the chat completion request\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to use\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # System message to set the assistant's behavior\n",
    "        {\"role\": \"user\", \"content\": \"Give me one paragraph on penguins\"}  # User message to initiate the conversation\n",
    "    ],\n",
    "    stream=True  # Enable streaming responses\n",
    ")\n",
    "\n",
    "# Capture the chat output in real-time\n",
    "chat_output = \"\"\n",
    "for chunk in chat_completion:\n",
    "    delta = chunk.choices[0].delta\n",
    "    content = getattr(delta, 'content', None)  # Safely get the content attribute\n",
    "    if content:\n",
    "        print(content, end='')  # Print without newline to maintain the flow\n",
    "        chat_output += content\n",
    "\n",
    "# API endpoint and headers for TTS\n",
    "url = \"https://api.openai.com/v1/audio/speech\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Data payload for the TTS request\n",
    "data = {\n",
    "    \"model\": \"tts-1-hd\",\n",
    "    \"voice\": \"onyx\",\n",
    "    \"input\": chat_output,  # Use chat output as input for TTS\n",
    "    \"response_format\": \"mp3\"  # Use MP3 format for response\n",
    "}\n",
    "\n",
    "# Make the TTS request with streaming enabled\n",
    "response = requests.post(url, headers=headers, json=data, stream=True)\n",
    "\n",
    "# Check if the TTS request was successful\n",
    "if response.status_code == 200:\n",
    "    buffer = BytesIO()\n",
    "\n",
    "    # Save audio chunks to file and buffer\n",
    "    with open(speech_file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                buffer.write(chunk)\n",
    "    \n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Read and play the audio from the buffer\n",
    "    data, samplerate = sf.read(buffer)\n",
    "    sd.play(data, samplerate)\n",
    "    sd.wait()  # Wait until the audio playback is done\n",
    "\n",
    "    print(f\"Audio saved to {speech_file_path}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant Output to TTS for Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize an empty list to store the results\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Append the delta value (partial text) to the results list\n",
    "        self.results.append(delta.value)\n",
    "        # Call the method to update the Jupyter Notebook cell\n",
    "        self.update_output()\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        # Clear the current output in the Jupyter Notebook cell\n",
    "        clear_output(wait=True)\n",
    "        # Join all the text fragments stored in results to form the complete markdown content\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        # Display the markdown content in the Jupyter Notebook cell\n",
    "        display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    \n",
    "    instructions=\"\"\" \n",
    "        You are a helpful assistant.\n",
    "    \"\"\",  # Instructions for the assistant.\n",
    "    \n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new assistant thread with an initial user message\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Give me one paragraph on penguins\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream the assistant's response\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    assistant_id=assistant.id,  # Specify the assistant ID.\n",
    "    event_handler=EventHandler(),  # Use the custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    \"\"\"Custom event handler for processing assistant events.\"\"\"\n",
    "\n",
    "    def __init__(self, batch_interval=5):\n",
    "        super().__init__()\n",
    "        self.results = []  # Initialize an empty list to store the results\n",
    "        self.tts_url = \"https://api.openai.com/v1/audio/speech\"\n",
    "        self.tts_headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        self.tts_model = \"tts-1-hd\"\n",
    "        self.voice = \"onyx\"\n",
    "        self.buffer = BytesIO()\n",
    "        self.batch_interval = batch_interval  # Time interval for batching in seconds\n",
    "        self.last_batch_time = time.time()\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"Handle the event when there is a text delta (partial text).\"\"\"\n",
    "        # Append the delta value (partial text) to the results list\n",
    "        text = delta.value\n",
    "        self.results.append(text)\n",
    "        # Call the method to update the Jupyter Notebook cell\n",
    "        self.update_output()\n",
    "\n",
    "        # Check if it's time to send a batch to TTS\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_batch_time >= self.batch_interval:\n",
    "            self.batch_to_tts()\n",
    "            self.last_batch_time = current_time\n",
    "\n",
    "    def update_output(self):\n",
    "        \"\"\"Update the Jupyter Notebook cell with the current markdown content.\"\"\"\n",
    "        # Clear the current output in the Jupyter Notebook cell\n",
    "        clear_output(wait=True)\n",
    "        # Join all the text fragments stored in results to form the complete markdown content\n",
    "        markdown_content = \"\".join(self.results)\n",
    "        # Display the markdown content in the Jupyter Notebook cell\n",
    "        display(Markdown(markdown_content))\n",
    "\n",
    "    def batch_to_tts(self):\n",
    "        \"\"\"Send batched text to TTS model and play the audio.\"\"\"\n",
    "        text = \"\".join(self.results)\n",
    "        if not text:\n",
    "            return\n",
    "        data = {\n",
    "            \"model\": self.tts_model,\n",
    "            \"voice\": self.voice,\n",
    "            \"input\": text,\n",
    "            \"response_format\": \"mp3\"\n",
    "        }\n",
    "        response = requests.post(self.tts_url, headers=self.tts_headers, json=data, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    self.buffer.write(chunk)\n",
    "            self.buffer.seek(0)\n",
    "            data, samplerate = sf.read(self.buffer)\n",
    "            sd.play(data, samplerate)\n",
    "            sd.wait()\n",
    "            self.buffer.seek(0)\n",
    "            self.buffer.truncate(0)\n",
    "            self.results = []  # Clear the results after batching to TTS\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Create an assistant using the client library.\n",
    "assistant = client.beta.assistants.create(\n",
    "    model=\"gpt-4o\",  # Specify the model to be used.\n",
    "    instructions=\"You are a helpful assistant.\",  # Instructions for the assistant.\n",
    "    temperature=1,  # Set the temperature for response variability.\n",
    "    top_p=1,  # Set the top_p for nucleus sampling.\n",
    ")\n",
    "\n",
    "# Create a new assistant thread with an initial user message\n",
    "assistant_thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Give me one paragraph on penguins\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create an instance of the custom event handler\n",
    "event_handler = EventHandler(batch_interval=5)  # Adjust batch interval as needed\n",
    "\n",
    "# Stream the assistant's response\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=assistant_thread.id,  # Specify the thread ID.\n",
    "    assistant_id=assistant.id,  # Specify the assistant ID.\n",
    "    event_handler=event_handler,  # Use the custom event handler for processing events.\n",
    ") as stream:\n",
    "    stream.until_done()  # Continue streaming until the assistant has finished responding.\n",
    "\n",
    "# Ensure any remaining text is sent to TTS after streaming is done\n",
    "event_handler.batch_to_tts()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
