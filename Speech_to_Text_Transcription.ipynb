{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Audio - Whisper (Speech-to-Text) \n",
    "# Transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univeral Code Used for the Entire Notebook\n",
    "\n",
    "Let's set up our libraries and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI  # For OpenAI API and event handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Transcription\n",
    "#### Request Body\n",
    "\n",
    "**file** `file`  **Required**  \n",
    "The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n",
    "\n",
    "**model** `string`  **Required**  \n",
    "ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.\n",
    "\n",
    "**language** `string`  **Optional**  \n",
    "The language of the input audio. Supplying the input language in **ISO-639-1** format will improve accuracy and latency.\n",
    "\n",
    "**prompt** `string`  **Optional**  \n",
    "An optional text to guide the model's style or continue a previous audio segment. The **prompt** should match the audio language.\n",
    "\n",
    "**response_format** `string`  **Optional** Defaults to json  \n",
    "The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.\n",
    "\n",
    "**temperature** `number`  **Optional** Defaults to 0  \n",
    "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use **log probability** to automatically increase the temperature until certain thresholds are hit.\n",
    "\n",
    "**timestamp_granularities[]** `array`  **Optional** Defaults to segment  \n",
    "The timestamp granularities to populate for this transcription. **response_format** must be set to `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. **Note**: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/fdr_speech.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcript)\n",
    "print(\"\\n\\n\")\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/fdr_speech.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"json\",\n",
    "    temperature=0.0,\n",
    "    timestamp_granularities=[\"segment\"],\n",
    ")\n",
    "\n",
    "print(transcript)\n",
    "print(\"\\n\\n\")\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verbose_json with segment timestamp granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/fdr_speech.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"verbose_json\",\n",
    "    temperature=0.0,\n",
    "    timestamp_granularities=[\"segment\"],\n",
    ")\n",
    "\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verbose_json\n",
    "This transcription is a detailed output from a speech-to-text model that transcribed President Franklin D. Roosevelt's speech delivered on December 8, 1941, following the attack on Pearl Harbor. Hereâ€™s a breakdown of the key components in the transcription data:\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Text**:\n",
    "   - This is the main body of the transcribed speech text. It captures the entirety of the speech delivered by Roosevelt, describing the events of the Japanese attack on Pearl Harbor, the resulting damage, and the United States' response.\n",
    "\n",
    "2. **Task**:\n",
    "   - The task is labeled as `transcribe`, indicating the primary function was to convert spoken words from an audio file into text.\n",
    "\n",
    "3. **Language**:\n",
    "   - The transcription was identified as being in `english`.\n",
    "\n",
    "4. **Duration**:\n",
    "   - The duration of the audio file is given as `520.4299926757812` seconds, indicating the length of the audio that was transcribed.\n",
    "\n",
    "5. **Segments**:\n",
    "   - The transcription is broken down into segments, each of which includes:\n",
    "     - **ID**: A unique identifier for each segment.\n",
    "     - **Seek**: The point in the audio where this segment begins.\n",
    "     - **Start** and **End**: The timestamps for the beginning and end of each segment.\n",
    "     - **Text**: The transcribed text for that particular segment.\n",
    "     - **Tokens**: Encoded representations of the segment text used by the model.\n",
    "     - **Temperature**: The model's temperature setting, which affects randomness in text generation.\n",
    "     - **Avg_logprob**: The average log probability of the tokens, indicating the confidence of the transcription.\n",
    "     - **Compression_ratio**: The ratio indicating the compression level applied.\n",
    "     - **No_speech_prob**: The probability that no speech was detected in this segment.\n",
    "\n",
    "### Detailed Explanation\n",
    "\n",
    "1. **Main Text**:\n",
    "   - The transcribed text is a historical speech by Roosevelt, informing Congress about the attack on Pearl Harbor by Japan. It details the events, the diplomatic context, and calls for action against Japan.\n",
    "\n",
    "2. **Task and Language**:\n",
    "   - The model's task was to transcribe spoken English from an audio file, accurately converting it into written text.\n",
    "\n",
    "3. **Segments**:\n",
    "   - Each segment represents a portion of the speech. Breaking down the text into segments helps manage large transcriptions and allows for detailed analysis of each part.\n",
    "\n",
    "4. **Metadata in Segments**:\n",
    "   - **ID** and **Seek** help in tracking and locating specific parts of the audio.\n",
    "   - **Start** and **End** times define the exact timing for each segment in the audio.\n",
    "   - **Tokens** are used internally by the model to process and generate text.\n",
    "   - **Temperature** controls the randomness; a setting of `0.0` means the model outputs are deterministic.\n",
    "   - **Avg_logprob** provides insight into the model's confidence; lower values generally indicate higher confidence.\n",
    "   - **Compression_ratio** gives an idea of the text's density or how much information is packed into the segment.\n",
    "   - **No_speech_prob** indicates the likelihood that the segment contains no speech, which is useful for identifying silent or non-speech segments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verbose_json with word timestamp granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/fdr_speech.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"verbose_json\",\n",
    "    temperature=0.0,\n",
    "    timestamp_granularities=[\"word\"],\n",
    ")\n",
    "\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verbose_json with word timestamp granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Segments vs. Words Metadata**:\n",
    "   - **First Transcription**: Contains metadata broken into `segments`, each with attributes like `id`, `seek`, `start`, `end`, `text`, `tokens`, `temperature`, `avg_logprob`, `compression_ratio`, and `no_speech_prob`.\n",
    "   - **Second Transcription**: Contains metadata broken into individual `words`, each with `word`, `start`, and `end` attributes.\n",
    "\n",
    "2. **Segment Attributes (First Transcription)**:\n",
    "   - **id**: Unique identifier for each segment.\n",
    "   - **seek**: The point in the audio where the segment begins.\n",
    "   - **start** and **end**: Timestamps for the beginning and end of each segment.\n",
    "   - **text**: The transcribed text for the segment.\n",
    "   - **tokens**: Encoded representations of the segment text used by the model.\n",
    "   - **temperature**: The model's temperature setting, affecting randomness in text generation.\n",
    "   - **avg_logprob**: The average log probability of the tokens, indicating the confidence of the transcription.\n",
    "   - **compression_ratio**: The ratio indicating the compression level applied.\n",
    "   - **no_speech_prob**: Probability that no speech was detected in the segment.\n",
    "\n",
    "3. **Word Attributes (Second Transcription)**:\n",
    "   - **word**: The individual word transcribed.\n",
    "   - **start** and **end**: Timestamps for the start and end of each word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/fdr_speech.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"text\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### srt (SubRip Subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/fdr_speech.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"srt\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vtt (Web Video Text Tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/fdr_speech.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"vtt\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/acronym_audio.mp4\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"json\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/acronym_audio.mp4\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"GPT-4o, GPT-4o mini\",\n",
    "    response_format=\"json\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/temperature_audio_test.mp4\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"json\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/temperature_audio_test.mp4\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"json\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/temperature_audio_test.mp4\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"json\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting with Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/temperature_audio_test.mp4\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Umm, let me think like, hmm... Okay, here's what I'm, like, thinking.\",\n",
    "    response_format=\"json\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/temperature_audio_test.mp4\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Umm, I think we should ahhh, do this thing.\",\n",
    "    response_format=\"json\",\n",
    "    temperature=0.9,\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/temperature_audio_test.mp4\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Let us discuss the topics of the day.\",\n",
    "    response_format=\"json\",\n",
    "    temperature=0.9,\n",
    ")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Vice President, Mr. Speaker, members of the Senate and the House of Representatives, yesterday, December 7th, 1941, a date which will live in infamy, the United States of America was suddenly and deliberately attacked by naval and air forces of the Empire of Japan. The United States was at peace with that nation, and at the solicitation of Japan, was still in conversation with its government and its emperor, looking toward the maintenance of peace in the Pacific. Indeed, one hour after Japanese air squadrons had commenced bombing in the American island of Oahu, the Japanese ambassador to the United States and his colleagues delivered to our Secretary of State a formal reply to a recent American message. While this reply stated that it seemed useless to continue the existing diplomatic negotiations, it contained no threat or hint of war or of armed attack. It will be recorded that the distance of Hawaii from Japan makes it obvious that the attack was deliberately planned many days or even weeks ago. During the intervening time, the Japanese government has deliberately sought to deceive the United States by false statements and expressions of hope for continued peace. The attack yesterday on the Hawaiian island has caused severe damage to American naval and military forces. I regret to tell you that very many American lives have been lost. In addition, American ships have been reported torpedoed on the high seas between San Francisco and Honolulu. Yesterday, the Japanese government also launched an attack against Malaya. Last night, Japanese forces attacked Hong Kong. Last night, Japanese forces attacked Guam. Last night, Japanese forces attacked the Philippine island. Last night, the Japanese attacked Wake island. And this morning, the Japanese attacked Midway island. Japan has therefore undertaken a surprise offensive extending throughout the Pacific area. The facts of yesterday and today speak for themselves. The people of the United States have already formed their opinions and well understand the implications for the very life and safety of our nation. As Commander-in-Chief of the Army and Navy, I have directed that all measures be taken for our defense, but always will our whole nation remember the character of the onslaught against us. No matter how long it may take us to overcome this premeditated invasion, the American people in their righteous might will win through to absolute victory. The will of the Congress and of the people, when I assert that we will not only defend ourselves to the uttermost, but will make it very certain that this form of treachery shall never again endanger us. Hostilities exist. There is no blinking at the fact that our people, our territory, and our interests are in grave danger. With confidence in our armed forces, with the unbounding determination of our people, we will gain the inevitable triumph. So help us God. I ask that the Congress declare that since the unprovoked and dastardly attack by Japan on Sunday, December 7, 1941, a state of war has existed between the United States and Ladies and gentlemen, the National Anthem.\n",
      "\n",
      "This transcript is of Franklin D. Roosevelt, the President of the United States at the time, addressing Congress on December 8, 1941, the day after the Japanese attack on Pearl Harbor. In this speech, Roosevelt describes the surprise attack by Japan and details the extensive damages and losses suffered by the United States. He stresses that the attack was premeditated despite ongoing diplomatic conversations with Japan. Roosevelt then assures Congress and the American people of the nation's resolve to defend itself and seek absolute victory. He concludes by requesting that Congress declares a state of war between the United States and Japan.\n"
     ]
    }
   ],
   "source": [
    "# Create a transcription of the audio file\n",
    "audio_file = open(\"./artifacts/fdr_speech.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    language=\"en\",\n",
    "    prompt=\"Transcribe the following audio file.\",\n",
    "    response_format=\"text\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(transcript)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will be given a transcript of an audio file. Your task is to summarize the text and tell me who is speaking.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": transcript\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
